{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate case\n",
    "\n",
    "## 1D data generation\n",
    "\n",
    "Define linear model $f(x) = ax + b$.\n",
    "\n",
    "Observe data $y = f(x) + \\epsilon$ with Gaussian noise $\\epsilon \\sim \\mathcal{N}(0,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x,a,b):\n",
    "    return a*x+b\n",
    "\n",
    "a = 5.\n",
    "b = 3.\n",
    "\n",
    "x = np.linspace(-1,1,100)\n",
    "y = f1(x,a,b)\n",
    "\n",
    "n = 10\n",
    "x_data = np.linspace(-1,1,n)\n",
    "y_data = f1(x_data,a,b) + np.random.randn(n)\n",
    "\n",
    "plt.plot(x,y,\"k-\",label=\"Ground Truth\")\n",
    "plt.plot(x_data,y_data,\"r.\",label=\"Data\")\n",
    "plt.legend()\n",
    "plt.xlim([-1,1])\n",
    "plt.ylim([-2,8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Graph Construction\n",
    "\n",
    "Define tensorflow graph for training linear regressor\n",
    "\n",
    "- placholder : $x, y$, shape (None,)\n",
    "\n",
    "- tensorflow variables : $\\hat{a},\\hat{b}$, shape ()\n",
    "\n",
    "- linear model : $\\hat{y} = \\hat{a}x + \\hat{b}$\n",
    "\n",
    "- loss : $\\frac{1}{N}\\sum_{i=1}^{N} (y_{i} - \\hat{y_{i}})$\n",
    "\n",
    "- optimizer : gradient descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x_ph = \n",
    "y_ph = \n",
    "\n",
    "a_hat = \n",
    "b_hat = \n",
    "\n",
    "y_pred = tf.multiply(x_ph,a_hat) + b_hat\n",
    "\n",
    "loss = 0.5 * tf.reduce_mean( tf.square(y_pred - y_ph) )\n",
    "\n",
    "# define optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "print(\"Tensorflow graph is contructed!!!\")\n",
    "print(\"x_ph is:\")\n",
    "print(\"type: \"+str(type(x_ph)))\n",
    "print(\"shape: \"+str(x_ph.shape))\n",
    "print(\"a_hat is:\")\n",
    "print(\"type: \"+str(type(a_hat)))\n",
    "print(\"shape: \"+str(a_hat.shape))\n",
    "print(\"y_pred is:\")\n",
    "print(\"type: \"+str(type(y_pred)))\n",
    "print(\"shape: \"+str(y_pred.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize TF variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "init = \n",
    "\n",
    "sess = \n",
    "sess.run(init)\n",
    "\n",
    "a_np, b_np = sess.run([a_hat,b_hat])\n",
    "print(\"Randomly initialized parameters\")\n",
    "print(\"a: %f\"%a_np)\n",
    "print(\"b: %f\"%b_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize linear model ( Find the best parameters )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepoch = 3000\n",
    "\n",
    "feed_dict = {x_ph:    ,y_ph:    }\n",
    "\n",
    "for epoch in range(nepoch):\n",
    "    loss_np,_ =\n",
    "    if (epoch%300) == 0:\n",
    "        print(\"[%d/%d] loss : %f\"%(epoch,nepoch,loss_np))\n",
    "print()\n",
    "    \n",
    "a_np, b_np = sess.run([a_hat,b_hat])\n",
    "print(\"Optimized parameters\")\n",
    "print(\"a: %f\"%a_np)\n",
    "print(\"b: %f\\n\"%b_np)\n",
    "print(\"Original parameters\")\n",
    "print(\"a: %f\"%a)\n",
    "print(\"b: %f\"%b)\n",
    "\n",
    "feed_dict = {x_ph:x}\n",
    "y_pred_np = sess.run(y_pred,feed_dict=feed_dict)\n",
    "plt.plot(x,y,\"k-\",label=\"Ground Truth\")\n",
    "plt.plot(x_data,y_data,\"r.\",label=\"Data\")\n",
    "plt.plot(x,y_pred_np,\"b-\",label=\"Linear Regression\")\n",
    "plt.legend()\n",
    "plt.xlim([-1,1])\n",
    "plt.ylim([-2,8])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate case\n",
    "\n",
    "## 2D data generation\n",
    "\n",
    "Now $x$ is a $d$-dimensional vector.\n",
    "\n",
    "Define linear model $f(x) = a^{t}x + b$.\n",
    "\n",
    "Observe data $y = f(x) + \\epsilon$ with Gaussian noise $\\epsilon \\sim \\mathcal{N}(0,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x,a,b):\n",
    "    return np.matmul(x,a)+b\n",
    "\n",
    "a = np.array([[2.],[1.]])\n",
    "b = 1.\n",
    "\n",
    "x1 = np.linspace(-1,1,100)\n",
    "x2 = np.linspace(-1,1,100)\n",
    "X1,X2 = np.meshgrid(x1,x2)\n",
    "x = np.concatenate([np.reshape(X1,[-1,1]),np.reshape(X2,[-1,1])],axis=1)\n",
    "y = f2(x,a,b)\n",
    "Y = np.reshape(y,[100,100])\n",
    "\n",
    "n = 50\n",
    "x_data = np.random.uniform(-1,1,size=(n,2))\n",
    "y_data = f2(x_data,a,b) + np.random.randn(n,1)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "ax.plot_surface(X1,X2,Y)\n",
    "ax.plot3D(x_data[:,0].flatten(),x_data[:,1].flatten(),y_data.flatten(),'r.',label=\"Data\")\n",
    "plt.legend()\n",
    "ax.set_xlim3d(-1,1)\n",
    "ax.set_ylim3d(-1,1)\n",
    "ax.set_zlim3d(-3,4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Graph Construction\n",
    "\n",
    "Define tensorflow graph for training linear regressor\n",
    "\n",
    "- placholder : $x, y$, shape: $x$ (None,2), $y$ (None,1)\n",
    "\n",
    "- tensorflow variables : $\\hat{a},\\hat{b}$, shape: $a$ (2,1), $b$ ()\n",
    "\n",
    "- linear model : $\\hat{y} = \\hat{a}x + \\hat{b}$\n",
    "\n",
    "- loss : $\\frac{1}{N}\\sum_{i=1}^{N} (y_{i} - \\hat{y_{i}})$\n",
    "\n",
    "- optimizer : gradient descent\n",
    "\n",
    "## Initialize graph\n",
    "## Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x_ph = \n",
    "y_ph = \n",
    "\n",
    "a_hat = \n",
    "b_hat =\n",
    "\n",
    "y_pred =\n",
    "\n",
    "loss =\n",
    "\n",
    "# define optimizer\n",
    "optimizer =\n",
    "train =\n",
    "\n",
    "# initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "a_np, b_np = sess.run([a_hat,b_hat])\n",
    "print(\"Randomly initialized parameters\")\n",
    "print(\"a: {:}\".format(a_np.flatten()))\n",
    "print(\"b: %f\\n\"%b_np)\n",
    "\n",
    "nepoch = 10000\n",
    "feed_dict = {x_ph:,y_ph:}\n",
    "for epoch in range(nepoch):\n",
    "    loss_np,_ =\n",
    "    if (epoch%1000) == 0:\n",
    "        print(\"[%d/%d] loss : %f\"%(epoch,nepoch,loss_np))\n",
    "    \n",
    "a_np, b_np = sess.run([a_hat,b_hat])\n",
    "print(\"Optimized parameters\")\n",
    "print(\"a: {:}\".format(a_np.flatten()))\n",
    "print(\"b: %f\\n\"%b_np)\n",
    "\n",
    "print(\"Original parameters\")\n",
    "print(\"a: {:}\".format(a.flatten()))\n",
    "print(\"b: %f\"%b)\n",
    "\n",
    "# Prediction\n",
    "feed_dict = {x_ph:}\n",
    "y_pred_np = \n",
    "Y_pred_np= np.reshape(y_pred_np,[100,100])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "ax.plot_surface(X1,X2,Y,color=\"k\")\n",
    "ax.plot3D(x_data[:,0].flatten(),x_data[:,1].flatten(),y_data.flatten(),'r.',label=\"Data\")\n",
    "plt.legend()\n",
    "ax.set_xlim3d(-1,1)\n",
    "ax.set_ylim3d(-1,1)\n",
    "ax.set_zlim3d(-3,4)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(X1,X2,Y_pred_np,color=\"b\")\n",
    "ax.plot3D(x_data[:,0].flatten(),x_data[:,1].flatten(),y_data.flatten(),'r.',label=\"Data\")\n",
    "\n",
    "plt.legend()\n",
    "ax.set_xlim3d(-1,1)\n",
    "ax.set_ylim3d(-1,1)\n",
    "ax.set_zlim3d(-3,4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Regression (Non-linear Regression)\n",
    "\n",
    "## Non-linear 1D data generation\n",
    "\n",
    "Now, our underlying model is not a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f3(x):\n",
    "    return np.sinc(x)\n",
    "\n",
    "x = np.linspace(-2*np.pi,2*np.pi,100)\n",
    "y = f3(x)\n",
    "\n",
    "n = 500\n",
    "x_data = np.linspace(-2*np.pi,2*np.pi,n) + 0.05*np.random.randn(n)\n",
    "y_data = f3(x_data) + 0.05*np.random.randn(n)\n",
    "\n",
    "plt.plot(x,y,\"k-\",label=\"Ground Truth\")\n",
    "plt.plot(x_data,y_data,\"r.\",label=\"Data\")\n",
    "plt.legend()\n",
    "plt.xlim([-2*np.pi,2*np.pi])\n",
    "plt.ylim([-1,1.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Regression\n",
    "\n",
    "<img src=\"img/kr_img0.jpg\">\n",
    "\n",
    "$K(x,y) \\triangleq \\exp\\left(-0.5\\lambda^{-1}(x-y)^{2}\\right)$\n",
    "\n",
    "$f(x) = \\sum_{i=1}^{k} w_{i} K(x,\\mu_{i})$\n",
    "\n",
    "### Matrix form\n",
    "\n",
    "$f(x) = k(x) w $\n",
    "\n",
    "where $w = [ w_{i} ]_{i=1}^{k}$ and $k(x)$ is $k$-dimensional vector\n",
    "\n",
    "$[k(x)] = k_{i}(x)$\n",
    "\n",
    "$k_{i}(x) = k(x,\\mu_{i})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Graph Construction\n",
    "\n",
    "Define tensorflow graph for training kernel regressor\n",
    "\n",
    "- placholder : $x, y$\n",
    "\n",
    "- placholder : $\\mu = [ \\mu_{i} ]_{i=1}^{k}, \\lambda^{-1}$\n",
    "\n",
    "- tensorflow variables : $w = [ w_{i} ]_{i=1}^{k}$\n",
    "\n",
    "- kernel regressor : $\\hat{y} = \\sum_{i=1}^{k} w_{i} k(x,x_{i})$\n",
    "\n",
    "- loss : $\\frac{1}{N}\\sum_{i=1}^{N} (y_{i} - \\hat{y_{i}})$\n",
    "\n",
    "- optimizer : gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_kernel = 20 # the number of mu\n",
    "mu = np.linspace(-2*np.pi,2*np.pi,n_kernel) # make mu\n",
    "inv_lambda = 1e1\n",
    "\n",
    "x_ph = tf.placeholder(tf.float32,shape=(None,1))\n",
    "y_ph = tf.placeholder(tf.float32,shape=(None,1))\n",
    "\n",
    "mu_ph = tf.placeholder(tf.float32,shape=(n_kernel,1))\n",
    "inv_lambda_ph = tf.placeholder(tf.float32,shape=())\n",
    "\n",
    "print(\"Define place holders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Form\n",
    "\n",
    "Let $\\hat{Y} = [\\hat{y_{i}}] = [k(x_{i})w]$.\n",
    "\n",
    "Then,\n",
    "\n",
    "$\\hat{Y} = Kw$ where $K_{ij} = k(x_{i},\\mu_{j})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Matrix $D$\n",
    "\n",
    "$D$ is a $n\\times k$ matrix whose element is\n",
    "\n",
    "$D_{ij} = (x_i - \\mu_j)^{2}$\n",
    "\n",
    "### Tensorflow style\n",
    "\n",
    "Let $X = [x_{i}]^{n}_{i=1}$ (vector)\n",
    "\n",
    "$D = X^{2} - 2X\\mu^{t} + (\\mu^{2})^{t}$\n",
    "\n",
    "Then, the kernel matrix is $K=\\exp(-0.5\\lambda^{-1}D)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = # X^2\n",
    "mu_norm = # mu^2\n",
    "\n",
    "x_norm = tf.reshape(x_norm, [-1, 1])\n",
    "mu_norm = tf.reshape(mu_norm, [1, -1])\n",
    "\n",
    "squared_dist = # X^2 - 2 X mu + mu^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Regressor and Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = # exp(-0.5*inv_lambda*D)\n",
    "    \n",
    "w_hat = # define w as tensorflow variable\n",
    "\n",
    "y_pred = # kernel * w_hat\n",
    "\n",
    "loss = # loss\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "w_np = sess.run(w_hat)\n",
    "print(\"Randomly initialized parameters\")\n",
    "print(\"w: {:}\\n\".format(w_np.flatten()))\n",
    "\n",
    "nepoch = 10000\n",
    "feed_dict = {x_ph:x_data[:,np.newaxis],y_ph:y_data[:,np.newaxis],mu_ph:   ,inv_lambda_ph:   }\n",
    "\n",
    "for epoch in range(nepoch):\n",
    "    loss_np,_ = sess.run([loss,train],feed_dict=feed_dict)\n",
    "    if (epoch%1000) == 0:\n",
    "        print(\"[%d/%d] loss : %f\"%(epoch,nepoch,loss_np))\n",
    "\n",
    "w_np = sess.run(w_hat)\n",
    "print(\"\\nOptimized parameters\")\n",
    "print(\"w: {:}\".format(w_np.flatten()))\n",
    "\n",
    "feed_dict = {x_ph:x[:,np.newaxis],mu_ph:mu[:,np.newaxis],inv_lambda_ph:inv_lambda}\n",
    "y_pred_np = sess.run(y_pred,feed_dict=feed_dict)\n",
    "\n",
    "plt.plot(x,y,\"k-\",label=\"Ground Truth\")\n",
    "plt.plot(x_data,y_data,\"r.\",label=\"Data\")\n",
    "plt.plot(x,y_pred_np,\"b-\",label=\"Kernel Regression\")\n",
    "plt.legend()\n",
    "plt.xlim([-2*np.pi,2*np.pi])\n",
    "plt.ylim([-1,1.5])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
